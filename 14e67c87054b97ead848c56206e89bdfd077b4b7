devmemory/commands/sync.py
  37f4d0493b22b793 12,14-16,89,110-121,146-158
devmemory/commands/config_cmd.py
  37f4d0493b22b793 78-86
devmemory/core/config.py
  37f4d0493b22b793 17,27,72
devmemory/core/memory_formatter.py
  37f4d0493b22b793 13,470-605
README.md
  37f4d0493b22b793 134-160,260-261,265-267
---
{
  "schema_version": "authorship/3.0.0",
  "git_ai_version": "1.1.4",
  "base_commit_sha": "14e67c87054b97ead848c56206e89bdfd077b4b7",
  "prompts": {
    "37f4d0493b22b793": {
      "agent_id": {
        "tool": "cursor",
        "id": "3c89c154-09c0-48f4-a8c4-f693ab515c94",
        "model": "default"
      },
      "human_author": "Shahriyar Rzayev <rzayev.sehriyar@gmail.com>",
      "messages": [
        {
          "type": "user",
          "text": "Analyze https://github.com/entireio/cli  and https://entire.io understand what they do better than we.",
          "timestamp": "2026-02-17T14:16:53.909Z"
        },
        {
          "type": "tool_use",
          "name": "glob_file_search",
          "input": {
            "globPattern": "*.md",
            "targetDirectory": "/home/shako/REPOS/Indie-Hacking/ai-dev-memory/.devmemory/knowledge"
          }
        },
        {
          "type": "user",
          "text": "Implement the plan as specified, it is attached for your reference. Do NOT edit the plan file itself.\n\nTo-do's from the plan have already been created. Do not create them again. Mark them as in_progress as you work, starting with the first one. Don't stop until you have completed all the to-dos.",
          "timestamp": "2026-02-17T14:38:02.347Z"
        },
        {
          "type": "tool_use",
          "name": "todo_write",
          "input": {}
        },
        {
          "type": "assistant",
          "text": "### 1. What Entire does (CLI + product)\n\n**High-level idea**\n\n- **Entire** is a git-integrated context capture system for AI-assisted development.\n- It **hooks into your git workflow** via CLI + git hooks so that **every AI agent session** (Claude Code, Gemini CLI, etc.) is **checkpointed and linked to commits**.\n- Result: for any commit, you can see **the conversation, prompts, responses, and files touched** that produced it.\n\n**Key capabilities (from `entireio/cli` and `entire.io`)**  \nSources: [`entireio/cli`](https://github.com/entireio/cli), [`entire.io`](https://entire.io)\n\n- **Git-native checkpoints**\n  - Uses a **shadow branch** `entire/checkpoints/v1` to store **session metadata**: transcripts, prompts, files touched, timestamps.\n  - **Your main branch’s history stays clean**; checkpoints live in a separate branch but are tightly linked to specific commits.\n  - Supports **manual-commit strategy** (checkpoint when a commit is made) and **auto-commit strategy** (checkpoint each agent response).\n\n- **Workflow integration**\n  - Works with **Claude Code** and **Gemini CLI** today; more agents planned (Copilot CLI, OpenCode, etc.).\n  - `entire enable` installs the hooks; `entire status` shows current session & strategy.\n  - **No extra UI**: everything runs from terminal + your existing editor; context is in git.\n\n- **Time-travel & recovery**\n  - `entire rewind` lets you **rewind to a previous checkpoint** within a session (safe “save points”).\n  - `entire resume` restores **latest checkpointed session metadata** for a branch and prints commands to keep going.\n  - This is framed as: **“recover instantly when an agent goes sideways”**.\n\n- **Understanding intent & history**\n  - Marketing focuses on **“every commit tells a story; now you can read it”**.\n  - For a commit you can see:\n    - The **code diff**\n    - The **session transcript** (prompt/response)\n    - Which **agent** (Claude/Gemini) was used\n    - The **developer** and timing\n  - This is targeted at:\n    - **Onboarding** (“why was this written this way?”)\n    - **Audit & compliance** (traceability of AI-generated code)\n    - **Debugging and maintenance** (understand decisions, not just changes).\n\n- **Config & features**\n  - Project-level `.entire/settings.json` and local overrides `settings.local.json`.\n  - Options for:\n    - Strategy: `manual-commit` vs `auto-commit`\n    - Logging, telemetry, automatic push of checkpoint branch.\n    - **Auto-summarization**: can auto-run an AI summarizer at commit time to generate checkpoint summaries.\n\n- **Positioning**\n  - **“Every commit is a checkpoint: code + the session behind it.”**\n  - **“No hosted service”** in the default story: everything lives in your git repo; you keep the data.\n  - Designed to be **agent-agnostic infrastructure for AI-assisted coding**.\n\n\n---\n\n### 2. What DevMemory/ai-dev-memory does today\n\nFrom your context + knowledge files:\n\n- **High-level idea**\n  - DevMemory is an **Automated Memory System (AMS)–backed tool** that:\n    - Ingests **git + AI session data** (via git-ai / hooks, etc.).\n    - **Saves structured memories** into a **Redis-based AMS** with semantic search.\n    - Provides CLI commands like `devmemory sync`, `devmemory search`, and `devmemory why` for **code archaeology** and **intent discovery**.\n\n- **Architecture**\n  - **CLI shell**\n    - Entry point in `devmemory/cli.py` implemented with **Typer**.\n    - Each command has:\n      - Typer wiring in `devmemory/cli.py`.\n      - Implementation in `devmemory/commands/<name>.py` (e.g. `why.py`).\n      - Core logic in `devmemory/core/*`:\n        - `ams_client.py` — HTTP client for Redis AMS.\n        - `git_ai_parser.py` — parse git + AI agent outputs.\n        - `memory_formatter.py` — build structured memory records with topics/entities.\n        - `utils.py` — git repo helpers, shell commands.\n  - **Backend**\n    - Uses **Redis Agent Memory Server (AMS)**, chosen over Pinecone/Weaviate/etc. because:\n      - Redis infra is familiar / battle-tested.\n      - AMS handles **embeddings, topic extraction, NER, deduplication**.\n      - Same Docker image provides both **REST API** and **MCP**.\n    - AMS does:\n      - Embedding + similarity search.\n      - **Dedup** of repeated syncs.\n      - Topic/entity enrichment (optionally also via local enrichment).\n\n- **Memory model**\n  - You store **three conceptual types**:\n    1. **Commit summaries (semantic)**: why/who/what of each commit; AI contribution stats.\n    2. **File-level change memories (episodic)**: snippets for what changed in each file, tied to specific commits.\n    3. **Prompt conversations (semantic)**: the AI prompts/queries and dialogues that drove changes.\n  - This enables:\n    - Intent search: “why did we add caching?”\n    - Implementation search: “what changed in `ams_client.py`?”\n\n- **Key commands / behaviors (from context)**\n  - `devmemory sync`\n    - Grabs recent git + AI information (e.g., git-ai notes, commit infos).\n    - Sends batched memories to AMS.\n    - Supports:\n      - `batch_size` for large payloads.\n      - `local_enrichment` vs AMS enrichment.\n      - Dry run mode, CLI feedback.\n  - `devmemory search`\n    - Searches across AMS memories with optional **recency boost**.\n    - Re-ranks results to favor recent work if asked.\n  - `devmemory why`\n    - **Code archaeology command**:\n      - Given a file (and optionally a symbol), fetches relevant commit/memory history.\n      - Truncates context using `tiktoken` to fit model windows.\n      - Synthesizes: “why does this file/function look like this; what led to it.”\n  - **Hooks & gotchas**\n    - Post-commit hook uses:\n      - `(sleep 2 && devmemory sync --latest 2>/dev/null) &` to avoid blocking git and to let git-ai write its notes.\n    - Search and sync are careful about AMS pagination (100 results/page, `next_offset`).\n\n- **Positioning / focus**\n  - Focused on:\n    - **Semantic memory** for a repo using **Redis AMS** as an external knowledge store.\n    - **Flexible search and “why” synthesis** over commits, files, and AI sessions.\n  - Less emphasis (so far) on:\n    - Git-native rewind or time-travel.\n    - Multi-agent orchestration.\n    - Distribution/install story beyond Python/venv.\n  - Very strong on:\n    - **Memory structure**, enrichment, and search semantics.\n    - Tight coupling to a powerful memory server rather than only storing data in git.\n\n\n---\n\n### 3. Comparison: positioning & feature set\n\n**How they capture context**\n\n- **Entire**\n  - Captures **AI sessions as they happen**, with strong tie to **git commits** and a dedicated **checkpoints branch**.\n  - The **session is primary**: transcripts, prompts, tool states, etc. linked to commit.\n  - Data lives **inside git**; no extra DB by default.\n\n- **DevMemory**\n  - Captures **memories derived from git + AI artifacts** and sends them to **Redis AMS**.\n  - The **memory graph is primary**: commit summaries, code diffs, prompts, all turned into structured semantic records.\n  - Data lives in **an external AMS**, not in git.\n\n**Core user questions**\n\n- **Entire optimizes for:**\n  - “**What AI conversation produced this commit?**”\n  - “**How do I rewind this messy agent session safely?**”\n  - “**Can I see the exact prompts/responses for this change for compliance or debugging?**”\n\n- **DevMemory optimizes for:**\n  - “**Why does this file/function look like this?**” (`devmemory why`)\n  - “**What were the important decisions and intents over time for this repo?**”\n  - “**Search my repo’s history and AI context by semantic intent.**”\n\n**Interaction model**\n\n- **Entire**\n  - Commands: `entire enable`, `status`, `rewind`, `resume`, `explain`, etc.\n  - Core flows:\n    - **Set and forget**: enable once, then it transparently tracks sessions.\n    - **When stuck**: run `entire rewind` or `entire explain` around a commit/session.\n\n- **DevMemory**\n  - Commands: `devmemory sync`, `search`, `why`, and AMS-related operations.\n  - Core flows:\n    - **After/between work**: sync new memories to AMS.\n    - **When curious**: run `devmemory why <file> [symbol]` or `search \"<question>\"`.\n\n**Data model & infra**\n\n- **Entire**\n  - **Git-only** storage.\n  - No additional infra needed: just the CLI and git.\n  - Strong story for:\n    - **Self-contained repos** (all history, including AI context, lives in git).\n    - **Auditable, portable data**.\n\n- **DevMemory**\n  - Requires **Redis AMS** (container / infra) plus:\n    - HTTP client, optional MCP access.\n  - In return, you get:\n    - **Vector search**, topic/entity extraction, dedup built-in.\n    - A general-purpose **memory server** that other tools/agents can query.\n\n**UX and polish**\n\n- **Entire**\n  - Very polished **README and marketing site**.\n  - Clear **“why this matters” narrative** targeted at teams and enterprises.\n  - **Single-command bootstrap**: `curl ... | bash`, then `entire enable`.\n  - Rich troubleshooting docs; strong emphasis on a production-grade experience.\n\n- **DevMemory**\n  - Strong **technical architecture** and integrations.\n  - Docs are more **developer-centric** and focused on behavior of the CLI + AMS.\n  - Less marketing polish (by design right now), more of a **power-user tool**.\n\n\n---\n\n### 4. Where Entire is clearly ahead (today)\n\n- **Git-native checkpointing and rewind**\n  - Entire offers **first-class “checkpoint and rewind” semantics**, making it feel like **save slots** for AI-assisted sessions.\n  - This is **developer-experience gold**: when an AI “goes sideways”, you can **rewind safely**.\n  - DevMemory, as-is, focuses on **search and explanation**, not **state restoration**.\n\n- **Zero-additional-infra story**\n  - Entire: **no DB**; everything is in git. This dramatically lowers friction—especially for teams who don’t want to operate Redis/AMS infra.\n  - DevMemory: needs **Redis AMS** (or similar) running, so there is an **infra tax**.\n\n- **Multi-agent support and positioning**\n  - Entire leans into **“works with your agents”** (Claude Code, Gemini now, others planned).\n  - The whole pitch is: **“wire this into your agents”**, not just “a general memory tool”.\n  - DevMemory integrates with git-ai and AMS but doesn’t yet have the same broad, plug-and-play agent story at the marketing layer.\n\n- **Install and onboarding UX**\n  - `curl https://entire.io/install.sh | bash` and `entire enable` is **very low friction** and highly standardized.\n  - Detailed README and docs show **typical workflows**, diagrams, and troubleshooting.\n  - DevMemory’s install story is more **Python/venv + AMS setup**; excellent for Python folks but less “one-line for any dev”.\n\n- **Enterprise / audit framing**\n  - Entire strongly markets:\n    - **Traceability** for AI-generated code.\n    - **Clean commit history with side-band session logs.**\n  - This “audit & compliance” framing is something DevMemory hints at, but not as a **front-and-center product story**.\n\n- **Auto-summarization at commit time**\n  - Entire can automatically generate **AI summaries** for checkpoints during commit.\n  - DevMemory has very strong **search + “why” synthesis**, but the default story isn’t “every commit automatically gets a human-readable AI summary” in git itself.\n\n\n---\n\n### 5. Opportunities for DevMemory (if you want to close the gap)\n\nThese are suggestions; you can pick and choose based on your goals.\n\n- **Add git-native “checkpoint” + minimal rewind integration**\n  - Even without fully replicating Entire, DevMemory could:\n    - Option A: track **lightweight checkpoints in git** (e.g., a dedicated branch or tag scheme) while **still using AMS for rich memory**.\n    - Option B: provide integration with Entire-like behavior: e.g. `devmemory rewind` that:\n      - Uses git commands to restore working tree to a known state.\n      - Then rehydrates memory context from AMS.\n  - This would let you keep your **AMS-first architecture**, but still answer “can I safely jump back to before this AI change?”.\n\n- **Offer a “no external infra” mode**\n  - Consider a **local-only memory backend** option:\n    - Simple file/SQLite-backed store for small repos.\n    - Redis AMS used only when explicitly configured.\n  - This would give you a **“one-command try it” story** similar to Entire for individuals and small teams.\n\n- **Sharpen the product story around code archaeology vs checkpoints**\n  - Entire owns **“every commit is a checkpoint + story”**.\n  - DevMemory can clearly own:\n    - **“Forensics and archaeology for AI-assisted codebases”**\n    - **“Ask why your code looks this way; get a narrative built from commits + sessions.”**\n  - Making `devmemory why` the hero feature (with examples in README/landing) will highlight what you already do particularly well.\n\n- **Tighter developer UX and docs**\n  - Take inspiration from Entire’s README/website structure:\n    - Short **“Why DevMemory”** section with 3–4 crisp bullets.\n    - **Getting started** with a single “happy path” flow: install, run AMS (optional quick Docker command), `devmemory sync`, `devmemory why`.\n    - Clear **recipes**: onboarding a new engineer, investigating a flaky test’s history, generating release notes from memories.\n\n- **Optional: auto-summarization per commit using AMS memories**\n  - You already have:\n    - Structured commit memories.\n    - A search + summarization pipeline (`devmemory why`).\n  - You could add:\n    - A **post-commit hook** that uses AMS memories to generate a **short natural-language commit summary** and either:\n      - Stores it in AMS as a special memory type.\n      - Writes it into a **local file** or **annotates git notes** (like git-ai does).\n  - This gives a parallel to Entire’s automatic checkpoint summaries but **powered by your AMS**.\n\n---\n\n### Todo status\n\n- **summarize-entire**: completed (see section 1).  \n- **summarize-devmemory**: completed (section 2).  \n- **compare-features**: completed (section 3).  \n- **identify-advantages**: completed (section 4).  \n- **suggest-opportunities**: completed (section 5).\n\nIf you tell me your strategic focus (e.g. “I want DevMemory to be the best archaeology tool, not a checkpoint system”), I can refine this into a concrete roadmap with specific issues/features to implement.",
          "timestamp": "2026-02-17T14:38:10.994Z"
        },
        {
          "type": "user",
          "text": "Okay now do the analysis how we can be helpful for openclaw users.",
          "timestamp": "2026-02-17T14:51:09.348Z"
        },
        {
          "type": "assistant",
          "text": "### 1. First, clarify what OpenClaw users need\n\nAssuming OpenClaw is an AI coding/agent tool (similar to Claude Code / Gemini CLI but open-source / self-hostable), its users typically need:\n\n- **Code context**: “What changed, where, and when?”\n- **Intent/context history**: “Why did the agent (or I) implement it this way?”\n- **Safety net**: “If the agent makes a mess, how do I understand and fix it?”\n- **Team knowledge**: “How do we reuse what previous sessions already learned?”\n\nDevMemory can sit **next to OpenClaw** as a “memory + archaeology layer” that makes all OpenClaw sessions searchable and explainable across the repo.\n\n---\n\n### 2. Concrete ways DevMemory can help OpenClaw users\n\n#### A. Turn OpenClaw sessions into long-term, searchable memory\n\n- **Integration pattern**:\n  - After each OpenClaw run (or at meaningful checkpoints), send:\n    - Prompts, responses, selected diffs, high-level rationale → **DevMemory/AMS** via a small adapter.\n  - DevMemory then:\n    - Stores **semantic memories** (intent, decisions).\n    - Stores **episodic memories** (file-level diffs tied to commits).\n- **Benefit for OpenClaw users**:\n  - They can later run `devmemory search \"<question>\"` like:\n    - “Why did we change retry logic in the webhook client?”\n    - “Where did OpenClaw migrate this service to Postgres?”\n\n#### B. “Explain this file/function” inside OpenClaw, powered by `devmemory why`\n\n- OpenClaw can expose a command / UI action: **“Why does this look like this?”** that:\n  - Calls `devmemory why path/to/file.py [symbol]`\n  - Renders DevMemory’s synthesized answer (built from git + AMS memories) inline in OpenClaw.\n- **Benefit**:\n  - OpenClaw becomes much better at **code archaeology and onboarding** without re-implementing that logic.\n  - Users get **narratives**, not just raw diffs: “this was added to fix X, then extended for Y, refactored for Z.”\n\n#### C. Give OpenClaw a project-wide, cross-session memory\n\n- Today, individual OpenClaw sessions may be **stateless or short-lived**.\n- DevMemory’s Redis AMS can act as a **shared, cross-session memory service**:\n  - OpenClaw agents query AMS for:\n    - Previous decisions about patterns, APIs, conventions.\n    - Prior bug fixes in related areas.\n  - DevMemory already **extracts topics/entities** (e.g., “Redis”, “payment_service”) so OpenClaw can do targeted recall.\n- **Benefit**:\n  - OpenClaw stops “starting from zero” every run, and can align to **how this repo historically solves problems**.\n\n#### D. Better safety & debugging for OpenClaw-assisted changes\n\n- When OpenClaw introduces a bug, DevMemory helps users answer:\n  - “What chain of steps led to this change?”\n  - “Which earlier prompts/decisions were involved?”\n- Combining:\n  - git history\n  - OpenClaw’s session logs (pushed into DevMemory)\n  - DevMemory’s `why` and `search`\n- **Benefit**:\n  - Users can **debug agent mistakes faster**, and see if similar issues happened before.\n\n#### E. Team-level knowledge hub across tools (not just OpenClaw)\n\n- DevMemory is **tool-agnostic**: it can store memories from:\n  - OpenClaw sessions\n  - Other agents (Claude, Gemini, etc.)\n  - Manual notes / runbooks.\n- For OpenClaw users in a team:\n  - They can **search one place** for:\n    - “How did we previously migrate services to Kafka?”\n    - “What’s our convention for feature flags?”\n- **Benefit**:\n  - OpenClaw becomes part of a **broader ecosystem of shared repo memory**, not a silo.\n\n---\n\n### 3. Integration ideas to make this real\n\nIf you want, I can next:\n\n- Sketch a **minimal OpenClaw ↔ DevMemory integration design** (where to hook in, what payloads to send).\n- Propose **specific CLI/API contracts**:\n  - e.g. `openclaw --sync-devmemory` or a small Python/HTTP client OpenClaw can call.\n- Outline **UX flows**:\n  - “User runs OpenClaw → DevMemory auto-syncs → later `devmemory why`/`search` explains it.”",
          "timestamp": "2026-02-17T14:51:21.528Z"
        },
        {
          "type": "user",
          "text": "Let's improve the README making it more concise and powerful, making the devmemory why the hero feature. Also I would like to show how it is useful for coding agents - getting recent memories, searching for the memory, creating memory using MCP, etc.",
          "timestamp": "2026-02-17T18:34:53.322Z"
        },
        {
          "type": "tool_use",
          "name": "todo_write",
          "input": {}
        },
        {
          "type": "assistant",
          "text": "I’ll streamline the README to put `devmemory why` front and center, then tighten the agent integration story and examples. I’ll keep the structure simple and concise while preserving the most important flows.",
          "timestamp": "2026-02-17T18:35:08.746Z"
        },
        {
          "type": "assistant",
          "text": "I’ll update the README in smaller chunks so the patch context matches exactly, then tighten up the agent section and confirm everything renders cleanly.",
          "timestamp": "2026-02-17T18:36:24.776Z"
        },
        {
          "type": "tool_use",
          "name": "todo_write",
          "input": {}
        },
        {
          "type": "assistant",
          "text": "### What I changed\n\n- **Made `devmemory why` the hero**: The top of `README.md` now leads with a short value statement and a dedicated **“`devmemory why` (hero feature)”** section that explains what it does, what inputs it pulls together, and what questions it answers.\n- **Simplified and shortened**: Removed the long narrative demo and large sample output; replaced with a concise **Quick start**, **Core CLI**, and short explanations instead of walls of text.\n- **Explicit agent story**: Added a **“How coding agents use DevMemory”** section explaining MCP tools (`search_long_term_memory`, `create_long_term_memories`), how agents fetch recent memories, and how they persist new decisions.\n- **Kept essentials, cut noise**: Retained knowledge files, git hooks, stack, and configuration sections but in a more compact form and without emojis or verbose commentary, so the README feels sharper and more focused on why/why+agents.",
          "timestamp": "2026-02-17T18:37:50.448Z"
        },
        {
          "type": "user",
          "text": "DevMemory is a long‑term memory for AI coding agents that can explain why any file or function looks the way it does - but not only, isn't it? Cursor can use it for each session to get the memory without wasting tokens to reevaluate the project each time. So maybe we can also show that DevMemory helps in that way as well? Just try to investigate and understand product and then update README",
          "timestamp": "2026-02-17T18:41:19.911Z"
        },
        {
          "type": "assistant",
          "text": "I’ll tighten the positioning to highlight both “why-explanations” and “session memory reuse” for agents, then update the README copy accordingly.",
          "timestamp": "2026-02-17T18:41:33.644Z"
        },
        {
          "type": "assistant",
          "text": "### What I changed\n\n- **Broadened the one-line description** at the top of `README.md` to say DevMemory both explains “why code looks this way” **and** lets agents reuse that understanding across sessions **without re-reading the whole repo**.\n- **Updated the “Why DevMemory” bullets** to emphasize **agent-ready, session-to-session memory**, explicitly calling out that agents can fetch recent memories at task start and write new ones at the end instead of burning tokens rediscovering context.\n- **Rewrote the Cursor integration section** to be more concrete about:\n  - Agents using `search_long_term_memory` to pull relevant memories instead of scanning code.\n  - Agents using `create_long_term_memories` to persist what changed and why.\n  - Using `.devmemory/CONTEXT.md` as a compact briefing on branch switch.\n- Framed the overall effect as a **compounding loop that saves tokens and latency** by reusing stored knowledge rather than reevaluating the project each session.",
          "timestamp": "2026-02-17T18:41:49.799Z"
        },
        {
          "type": "user",
          "text": "Optional: auto-summarization per commit using AMS memories.\n\nWhat is the benefit of this feature from DevMemory perspective as Agent Memory Product.",
          "timestamp": "2026-02-19T17:59:46.075Z"
        },
        {
          "type": "assistant",
          "text": "Analyzing the benefits of auto-summarization per commit from DevMemory's perspective as an Agent Memory Product.",
          "timestamp": "2026-02-19T17:59:57.546Z"
        },
        {
          "type": "assistant",
          "text": "Analyzing the benefits of auto-summarization per commit from DevMemory's perspective as an Agent Memory Product:",
          "timestamp": "2026-02-19T18:00:06.151Z"
        },
        {
          "type": "assistant",
          "text": "## Benefits of Auto-Summarization Per Commit for DevMemory as an Agent Memory Product\n\n### 1. Higher-quality semantic memories for agent consumption\n\nCurrent state: DevMemory creates structured summaries from metadata (commit message, stats, prompts, file lists). These are factual but lack narrative context.\n\nWith auto-summarization: LLM-generated summaries capture:\n- Intent: why the change was made\n- Outcome: what problem it solved\n- Learnings: what was discovered during implementation\n- Friction points: blockers or tradeoffs encountered\n- Open items: follow-ups or known limitations\n\nResult: Agents get richer, more consumable memories optimized for understanding, not just metadata.\n\n### 2. Better search relevance and recall\n\nCurrent state: Agents searching for \"why did we add retry logic\" might match a commit message like \"feat: add retry logic\" but miss the context.\n\nWith auto-summarization: A summary like \"Added exponential backoff retry logic after production incident where transient network failures caused data loss. Initially tried fixed delays but exponential backoff performed better under load\" is much more findable via semantic search.\n\nResult: Agents find relevant context faster, reducing wasted searches and token spend.\n\n### 3. Token efficiency for agents\n\nCurrent state: Agents may need to read raw diffs, commit metadata, or multiple memory records to understand a change.\n\nWith auto-summarization: Agents read concise, structured summaries (100–300 tokens) instead of parsing:\n- Full commit diffs (often 500–2000+ tokens)\n- Multiple memory records\n- Raw git history\n\nResult: Faster agent sessions, lower token costs, better latency.\n\n### 4. Intent preservation across time\n\nCurrent state: Code diffs show what changed, but the \"why\" can be lost if commit messages are brief or missing.\n\nWith auto-summarization: Summaries preserve intent, decisions, and rationale at commit time, making them available to future agents.\n\nResult: Agents understand historical decisions even when commit messages are minimal.\n\n### 5. Compounding knowledge across commits\n\nCurrent state: Each commit summary is independent; agents must synthesize patterns themselves.\n\nWith auto-summarization: Summaries can reference related commits, creating a knowledge graph. For example: \"This refactor builds on the caching layer added in commit abc123, addressing the performance issues identified there.\"\n\nResult: Agents build understanding incrementally rather than rediscovering patterns each session.\n\n### 6. Faster agent onboarding for new sessions\n\nCurrent state: Agents starting a new session may need to analyze recent commits to understand recent changes.\n\nWith auto-summarization: Agents can quickly catch up by reading recent commit summaries (e.g., last 10–20 commits) instead of analyzing code changes.\n\nResult: Agents become productive faster, with less redundant analysis.\n\n### 7. Enhanced `devmemory why` synthesis\n\nCurrent state: `devmemory why` synthesizes from structured commit summaries, file diffs, and prompt context.\n\nWith auto-summarization: `devmemory why` has richer source material—narrative summaries that already capture intent and learnings—leading to better explanations.\n\nResult: More accurate and useful code archaeology.\n\n### 8. Differentiation from competitors\n\nEntire stores raw session transcripts; Git AI captures attribution metadata. DevMemory would offer AI-generated summaries optimized for agent consumption—a distinct value proposition.\n\nResult: Clear positioning as the \"agent-optimized memory layer\" rather than just a capture tool.\n\n### 9. Reduced redundancy in agent analysis\n\nCurrent state: Multiple agents may analyze the same commits independently to understand patterns.\n\nWith auto-summarization: Once a commit is summarized, all agents benefit from that analysis, avoiding repeated work.\n\nResult: More efficient use of agent compute and tokens.\n\n### 10. Better context for cross-session continuity\n\nCurrent state: Agents rely on `.devmemory/CONTEXT.md` and search, which may miss recent changes.\n\nWith auto-summarization: Agents can fetch recent commit summaries (e.g., last N commits) to quickly understand what changed since their last session.\n\nResult: Smoother continuity between agent sessions.\n\n---\n\n## Implementation considerations\n\n- Trigger: Run during `devmemory sync` (post-commit hook) or as a background job.\n- Cost: One LLM call per commit (non-blocking, failures logged but don't block sync).\n- Storage: Store as a new semantic memory type (e.g., `commit_summary_llm`) alongside existing structured summaries.\n- Quality: Use structured prompts to ensure summaries include intent, outcome, learnings, friction, and open items.\n- Deduplication: AMS deduplication prevents re-summarizing already-summarized commits.\n\n---\n\n## Summary\n\nAuto-summarization transforms DevMemory from a \"structured metadata store\" into an \"agent-optimized knowledge base\" where each commit becomes a rich, searchable narrative that agents can consume efficiently. This aligns with DevMemory's positioning as the memory layer that makes agents smarter across sessions, not just a capture tool.",
          "timestamp": "2026-02-19T18:00:12.716Z"
        },
        {
          "type": "user",
          "text": "Let's implement this feature, also update README accordingly",
          "timestamp": "2026-02-19T18:05:14.065Z"
        },
        {
          "type": "assistant",
          "text": "Implementing auto-summarization per commit. Reviewing the sync flow and LLM client, then adding the feature.",
          "timestamp": "2026-02-19T18:05:18.894Z"
        },
        {
          "type": "assistant",
          "text": "Implementing auto-summarization: adding the summarization function, config option, and integration into the sync flow.",
          "timestamp": "2026-02-19T18:05:24.775Z"
        },
        {
          "type": "assistant",
          "text": "Adding the summarization function and integrating it into the sync flow:",
          "timestamp": "2026-02-19T18:05:27.427Z"
        },
        {
          "type": "tool_use",
          "name": "todo_write",
          "input": {}
        },
        {
          "type": "assistant",
          "text": "Implementing auto-summarization: adding the summarization function, config option, and sync integration.",
          "timestamp": "2026-02-19T18:05:30.206Z"
        },
        {
          "type": "assistant",
          "text": "Adding the summarization function:",
          "timestamp": "2026-02-19T18:05:35.956Z"
        },
        {
          "type": "assistant",
          "text": "Adding the summarization function at the end of the file:",
          "timestamp": "2026-02-19T18:05:40.353Z"
        },
        {
          "type": "assistant",
          "text": "Fixing the memory ID generation:",
          "timestamp": "2026-02-19T18:05:52.246Z"
        },
        {
          "type": "assistant",
          "text": "Integrating summarization into the sync flow:",
          "timestamp": "2026-02-19T18:06:00.901Z"
        },
        {
          "type": "assistant",
          "text": "Adding CLI options for auto-summarization and updating the config command:",
          "timestamp": "2026-02-19T18:06:19.535Z"
        },
        {
          "type": "assistant",
          "text": "Checking the config command to add auto_summarize support:",
          "timestamp": "2026-02-19T18:06:22.985Z"
        },
        {
          "type": "assistant",
          "text": "Updating the config command to handle boolean values:",
          "timestamp": "2026-02-19T18:06:37.764Z"
        },
        {
          "type": "assistant",
          "text": "Updating the README to document auto-summarization:",
          "timestamp": "2026-02-19T18:06:43.850Z"
        },
        {
          "type": "assistant",
          "text": "Adding auto-summarization documentation to the README:",
          "timestamp": "2026-02-19T18:06:47.317Z"
        },
        {
          "type": "tool_use",
          "name": "todo_write",
          "input": {}
        },
        {
          "type": "assistant",
          "text": "Reading the README to find the correct insertion point:",
          "timestamp": "2026-02-19T18:06:56.551Z"
        },
        {
          "type": "assistant",
          "text": "Adding the auto-summarization section:",
          "timestamp": "2026-02-19T18:07:01.264Z"
        },
        {
          "type": "assistant",
          "text": "Checking for linting errors:",
          "timestamp": "2026-02-19T18:07:08.671Z"
        },
        {
          "type": "assistant",
          "text": "## Implementation Summary\n\n### 1. **Added LLM Summarization Function** (`devmemory/core/memory_formatter.py`)\n   - Created `generate_commit_summary()` that:\n     - Takes commit data (metadata, prompts, diffs, stats)\n     - Generates a narrative summary using LLM\n     - Captures intent, outcome, learnings, friction points, and open items\n     - Returns a memory dict ready for AMS storage\n     - Handles errors gracefully (returns `None` on failure)\n\n### 2. **Added Configuration Option** (`devmemory/core/config.py`)\n   - Added `auto_summarize: bool` field to `DevMemoryConfig` (default: `False`)\n   - Updated config loading/saving to handle the new field\n\n### 3. **Integrated into Sync Flow** (`devmemory/commands/sync.py`)\n   - Modified sync to generate summaries when `auto_summarize` is enabled\n   - Summaries are generated **non-blocking**—failures don't stop sync\n   - Summaries are stored separately and added to the total synced count\n   - User feedback shows summary generation status\n\n### 4. **Enhanced Config Command** (`devmemory/commands/config_cmd.py`)\n   - Updated `set` command to handle boolean values (true/false, 1/0, yes/no, on/off)\n   - Users can enable/disable with: `devmemory config set auto_summarize true`\n\n### 5. **Updated README**\n   - Added \"Auto-summarization\" section explaining:\n     - What summaries capture\n     - Benefits for agents (token efficiency, search relevance, faster onboarding)\n     - How to enable it\n   - Updated Configuration section to document `auto_summarize` option\n\n## Features\n\n- Non-blocking: Summarization failures don't interrupt sync\n- Token-efficient: Summaries are 100-300 tokens vs. full diffs (500-2000+ tokens)\n- Searchable: Summaries stored as semantic memories with `commit-summary` topic\n- Agent-optimized: Captures \"why\" and \"what we learned\" for better agent understanding\n- Configurable: Easy to enable/disable via config command\n\nThe feature is ready to use. Users can enable it with `devmemory config set auto_summarize true`, and summaries will be generated automatically during future syncs.",
          "timestamp": "2026-02-19T18:07:11.863Z"
        }
      ],
      "total_additions": 214,
      "total_deletions": 4,
      "accepted_lines": 212,
      "overriden_lines": 0
    }
  }
}
